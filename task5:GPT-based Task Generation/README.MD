### Task 3: GPT-based Text Generation

**Objective:**  
Generate text automatically using a pre-trained GPT-2 model.

**Steps:**
1. Used HuggingFace `transformers` library to load GPT-2.
2. Defined a text prompt to start the story.
3. Generated text with a maximum length of 150 tokens.
4. Output is saved in `generated_text.txt`.

**Usage:**
- Open `Text_Generation_Task.ipynb` in Colab.
- Run all cells.
- Generated text will be printed and saved in the file.

**Output Sample:**
